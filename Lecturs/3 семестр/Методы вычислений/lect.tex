\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage[english, russian] {babel}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{minted}
\usepackage{float}
\usepackage{amssymb}


\title{Методы вычислений}
\author{Никитенко Яна}


\begin{document}

\maketitle

\textbf{02.09.25}

\section{1 Раздел}
\textbf{Интерполяция функций одного аргумента}

Интерполяция - приближение.

\subsection{Параграф 1 - Постановка интерполяций}

Пусть заданна дискретным набором своих значений некоторая функция f 
а именно, данная функция определенна следующией таблицей своих значений 

тут пикча с табличкой 


, где $f_k=f(xk),\bigvee k =\overline{0,n} $

требуется указать(построить ) непрерывную на некоторой области функцию g(x)
такую что бы выполнялись следующие условия:  

\textbf{$g(x_k)=f_k,\bigvee k =\overline{0,n}$ (1) (ГУИ)}

\begin{figure} [H]
    \includegraphics[width=0.50\linewidth]{photo_5310113942493852121_y.jpg}
\end{figure}

\begin{figure} [H]
    \includegraphics[width=0.80\linewidth]{Без имени.png}
\end{figure}


01 x,x1,...x2 б.н будем называть \textbf{узлами интерполяций(узлами приближений)}

\vspace{3mm}

02 f (xk,fk), $\bigvee k =\overline{0,n}$ называется \textbf{интерпоплируемой(приближаемой) функций}

\vspace{3mm}

03 g(x) удовлетворяющей условиям (1) будем называть \textbf{интерполирующией
(приблежающий, интерполяционный) или  интерполянта }

\vspace{3mm}

04 условия (1) будем называть \textbf{главным условием интерполяции(ГУИ)}

\vspace{3mm}


В сформулированной задачи интерполции очевидно в качестве искомой интерполянты
\underline{ бесконечной количество искомой функции} 

\begin{figure} [H]
    \includegraphics[width=0.50\linewidth]{Без имени1.png}
\end{figure}


\subsection{Параграф - 2  Интерполяционный многочлен в общем виде}

В этом параграфе покажем что в качестве искомой интерполяный - задачи интерполяции(З.И)
может быть предложен алгебраический многочлен в степени n,
построенный по (n+1)-му по парно различному узлу интерполяции.

\vspace{3mm}



Такми образом для (n+1) узла интерполции  $x_0,x_1,...x_n$  осторожно попробуем построить
алгебраический многочлен $\rho_n(x) = a_nx+a_{n-1} -1 ... + a_1x^1+a_0$ (2)

Потребуем что бы алгебраический многочлен вида (2) удовлетворял ГУИ (1)

а именно что бы 

$\rho_n(x_0)=f_0$        \hspace{2mm} (2)          \hspace{5mm}   $a_x0^n+a_{n-1}x^{n-1}_0+...+a_1x_0+a_0=f_0$  

$\rho_n(x_1)=f_1$       \hspace{2mm}    $\Leftrightarrow $ \hspace{5mm}   $a_nx_1^n+a_{n-1}x^{n-1}_1+...+a_1x_1+a_1=f_1$  (3)

и т.д 

$\rho_n(x_n)=f_n$ \hspace{10mm} $a_n x_n^n+a_{n-1}x^{n-1}_n +...+a_1x_n+a_0=f_n$



Равенство (3) по своей алгебраической природе предствалвеют собой СЛАУ
(система линейных алгебраических уравнений) раззмеронсти 

СЛАУ$(n+1)x(n+1)$ отн. несущ.коэф.


Что бы решить СЛАУ (3) 

запишем определить $\Delta_3 =$
$\begin{pmatrix}$
$x_0^n & x_0^{n-1} & \cdots & x_0 & 1 \\$
$x_1^n & x_1^{n-1} & \cdots & x_1 & 1 \\$
$\vdots & \vdots & \ddots & \vdots & \vdots \\$
$x_n^n & x_n^{n-1} & \cdots & x_n & 1$
$\end{pmatrix}$

$=\dots \prod (x_j-x_i)\neq 0 $ (4)


Что бы определитель (4) нужно чтоб узел $x_j\neq x_i, если j\neq i$ (5)
это есть условие по парной различности узлов интерполции


Таким образом из выше изложенного можем получить следующие:

Определитель (4) отличен от нуля при условии (5), а седовательно СЛАУ (3) решив 
каким либо подходящим численным методом, сможем найти ее единтсвенное решение,
а именно значение искомых коэффицентов $a_0,a_1$

Найдя эти коэффиценты  и подставим их в искомое (2) явно аналитическую формулу для искоомого
предтсваления интерполянты:

$\rho_n(x_n)=a_nx^n+a_{n_1}+x^{n-1} + a_1x+a_0$

Попробуем найти коэффициенты $a_i$
. Мы хотим подставить (2) в качестве g(x), то
есть чтобы
Потребуем чтобы алгебраический многочлен  (2) удовлетворял ГУИ  (1), чтобы
выполнялись следующие равенства:

1. pn(x0) = f0, по этой же логике pn(x1) = f1


\begin{figure} [H]
    \includegraphics[width=0.50\linewidth]{Снимок экрана 2025-12-27 224514.png}
\end{figure}



Равенство (3) по своей алгебраической природе представляет собой систему
линейных алгебраических уравнений (СЛАУ) размерности (n + 1) * (n + 1) относительно
неизвестных коэффициентов интерполянты fn(x) a0, a1, ...an

Чтобы решить СЛАУ  (3) чтобы ее решить нужно чтобы ее главный определитель был
отличен от нуля

\begin{figure} [H]
    \includegraphics[width=0.50\linewidth]{Снимок экрана 2025-12-27 224923.png}
\end{figure}


Чтобы определитель  (4) был отличен от нуля нужно, чтобы узел
xj $\neq $ xi, если j = i (5)


(5) — условие попарной различности узлов интерполяции
Таким образом из выше изложенного можем получить следующее:

При условии (5) определитель  (4) будет отличен от нуля, а следовательно
СЛАУ  (3) будет иметь единственное решение. Соответственно решив СЛАУ

 (3) каким-либо численным методом, сможем найти ее единственное решение, а
именно значение искомых коэффициентов a0, a1, ..., an. В свою очередь найдя эти
коэффициенты и подставив из в исходное представление  (2), мы получим явную
аналитическую форму для исходного прдставлени интерполянты

$p_n(x) = a_n x^n + a_{n-1} x^{n-1} + ... + a_1 x_1 + a0 (6)$


Из выше изложенного, получаем следующий алгоритм построения интерполяционного
многочлена (И.М.) в общем виде:
По данным интерполяции $(x_k, f_k), k = \\overline{0,n}$

1. записать общий вид искомого многочлена (2); $P_k(x) = (2)$

2. Построить вспомогательную СЛАУ (3)

3. Решить СЛАУ (3)

4. Найдя на шаге 3 коэффициенты $a_n, a{n-1}, ...a0,$ подставить из в искомое представление
И.М. в общем виде записанный на шаге 1.


\textbf{Тут пропущенная лекция, могут быть ошибки}
\section{Параграф 3}

В предыдущем параграфе мы установили, что в случае попарно различных узлов интерполяции вспомогательная система (3) имеет единственное решение, а следовательно, искомая интерполянта вида (2) будет определена единственным образом.

Поскольку способ, описанный в предыдущем параграфе, имеет вычислительные ограничения с ростом числа узлов интерполяции, то, зная, что в задаче интерполяции (ЗИ) при условии (5) существует и притом единственное решение, далее будем решать ту же задачу, но иным способом.

Введем алгебраические многочлены:

\begin{equation}
    l_k(x), \quad k = 0, \dots, n; \quad l_k(x_j) = 
    \begin{cases}
        0, & k \neq j, \\
        1, & k = j.
    \end{cases}
    \tag{7}
\end{equation}

Уравнение (7) --- фундаментальный многочлен Лагранжа (ФМЛ).

При помощи таких ФМЛ построим многочлен

\begin{equation}
    L_n(x) = \sum_{k=0}^{n} f_k \cdot l_k(x).
    \tag{8}
\end{equation}

Здесь $l_0$ будет принимать значение 1 в точке $x_0$, $l_1$ в точке $x_1$ и так далее по индукции.

Покажем, что представление (8) действительно удовлетворяет главному условию интерполяции (ГУИ). Для этого подставим в него в качестве значения аргумента $x$ узел $x_j$, где $j = 0, \dots, n$:

\begin{equation}
    \begin{aligned}
        L_n(x_j) &\overset{(8)}{=} f_0 \cdot \underbrace{l_0(x_j)}_{0} + f_1 \cdot \underbrace{l_1(x_j)}_{0} + \dots + f_j \cdot \underbrace{l_j(x_j)}_{1} + \dots + f_n \cdot \underbrace{l_n(x_j)}_{0} \\
        &\overset{(7)}{=} f_j \cdot 1 = f_j, \quad \forall j = 0, \dots, n.
    \end{aligned}
    \tag{9}
\end{equation}

Таким образом, разложение вида (8) (линейная комбинация ФМЛ) действительно удовлетворяет главному условию интерполяции.

Но отметим, что пока представление (8) непригодно для нахождения значений интерполянты вне узловых точек (что необходимо для полного разрешения задачи интерполяции).

В этой связи, зная, что фундаментальные многочлены Лагранжа $l_k(x)$ в точках 
$x_0, x_1, \dots, x_{k-1}, x_{k+1}, \dots, x_n$ равны 0 в силу (8), применим основную теорему алгебры.

\subsubsection*{Небольшое отступление}

Рассмотрим квадратный трёхчлен:
\[
    ax^2 + bx + c = 0, \quad b^2 - 4ac \ge 0, \quad x_1, x_2 \text{ --- корни}.
\]
Тогда
\[
    ax^2 + bx + c = a(x - x_1)(x - x_2). \tag{10}
\]

Если там хорошие числа, то все норм.

Это утверждение можно сформулировать и обратно: если есть произведение $a(x - x_1)(x - x_2)$, где $a, x_1, x_2$ --- произвольные числа, то можно получить все множество парабол, но все они будут иметь нули в точках $x_1$ и $x_2$.

\subsubsection*{Возвращаемся обратно}

В результате ФМЛ можно записать в следующем виде:

\begin{equation}
    l_k(x) \big|_{k=0,\dots,n} = c_k (x - x_0)(x - x_1) \dots (x - x_{k-1})(x - x_{k+1}) \dots (x - x_n). \tag{11}
\end{equation}

Потребуем также, чтобы представление (11) удовлетворяло условию нормировки
\[
    l_k(x_k) = 1, \quad \forall k = 0, \dots, n;
\]
\[
    l_k(x_k) = c_k (x_k - x_0)(x_k - x_1) \dots (x_k - x_{k-1})(x_k - x_{k+1}) \dots (x_k - x_n) \Rightarrow
\]
\begin{equation}
    c_k \big|_{k=0,\dots,n} = \frac{1}{(x_k - x_0)(x_k - x_1) \dots (x_k - x_{k-1})(x_k - x_{k+1}) \dots (x_k - x_n)}. \tag{12}
\end{equation}

Таким образом, осуществляя последовательную подстановку сначала (12) в (11), а затем (11) в (8), мы получим искомую явную аналитическую формулу интерполяционного многочлена в форме Лагранжа:

\begin{equation}
    L_n(x) = \sum_{k=0}^{n} f_k \frac{(x - x_0)(x - x_1) \dots (x - x_{k-1})(x - x_{k+1}) \dots (x - x_n)}{(x_k - x_0)(x_k - x_1) \dots (x_k - x_{k-1})(x_k - x_{k+1}) \dots (x_k - x_n)}. \tag{13}
\end{equation}

Уравнение (13) --- интерполяционный многочлен в форме Лагранжа.



\textbf{Тут тоже пропущеннная лекция}
\section{Параграф 4 Интерполяционный многочлен в форме Ньютона}

В данном параграфе рассмотрим еще один способ построения интерполяционного многочлена (ИМ), 
существование и единственность которого были изучены в параграфе (1.1.2). При этом данный способ будет лишен недостатков предыдущих двух способов решения задачи интерполяции (ЗИ).

\textbf{3.1.1. Минутка школьной программы. ЛОЛ}

Если дан многочлен $P_2(x) = ax^2 + bx + c$, нам надо найти его коэффициенты:
\[
\begin{cases}
    P_2(x_0) = \dots = A, \\
    P_2'(x_0) = 2ax_0 + b = B, \\
    P_2''(x_0) = 2a = C.
\end{cases}
\tag{14}
\]
Тогда можем найти значения коэффициентов. А как найти производную?
\begin{equation}
    f'(x_0) = \lim_{x \to x_0} \frac{f(x_0 + \Delta) - f(x_0)}{x - x_0}. \tag{15}
\end{equation}
А что, если мы откажемся от классического понимания производной (так как нам тяжело вычислить предел)?

Для дальнейшего использования дадим ряд вспомогательных определений.

\paragraph*{Опр. 1.} Разделёнными разностями (РР) нулевого порядка функции будем называть её узловые значения:
\begin{equation}
    f : f(x_0), f(x_1), \dots, f(x_n). \tag{16}
\end{equation}

\paragraph*{Опр. 2.} РР 1-го порядка будем называть
\begin{equation}
    f(x_k; x_{k+1}) = \frac{f(x_{k+1}) - f(x_k)}{x_{k+1} - x_k}, \quad k = 0, \dots, n-1. \tag{17}
\end{equation}

\paragraph*{Опр. 3.} РР 2-го порядка будем называть выражение вида
\begin{equation}
    f(x_k; x_{k+1}; x_{k+2}) = \frac{f(x_{k+1}; x_{k+2}) - f(x_k; x_{k+1})}{x_{k+2} - x_k}, \quad k = 0, \dots, n-2. \tag{18}
\end{equation}

\paragraph*{Опр. 4. (Общее)} РР $l$-го порядка будем называть функцию $f$ следующего вида:
\begin{equation}
    f(x_k; x_{k+1}; \dots; x_{k+l-1}; x_{k+l}) = 
    \frac{f(x_{k+1}; \dots; x_{k+l}) - f(x_k; \dots; x_{k+l-1})}{x_{k+l} - x_k}, \quad k = 0, \dots, n-l. \tag{19}
\end{equation}

РР, указанные в приведённых определениях, можно рассматривать как дискретные приближённые аналоги соответствующих производных, понимаемых по классическому определению.

Соответственно, используя введённые РР, попробуем с их помощью восстановить искомый ИМ: $P_n(x) = L_n(x)$.

Для упрощения выскажем предположение, что интерполируемая функция $f$ сама является алгебраическим многочленом степени $n$.

В этом случае такая функция $f$ и её интерполяционный многочлен $P_n(x)$ в силу единственности такого многочлена будут тождественно равны друг другу, т.е. $\forall x \quad f(x) \equiv P_n(x)$.

Возьмём некоторую фиксированную точку $x$; для определённости считаем, что $x < x_0$. Попытаемся найти значение в этой точке $f(x)$. С этой целью будем привлекать РР в следующем порядке:
\begin{equation}
    f(x; x_0) \overset{\text{по опр}}{=} \frac{f(x_0) - f(x)}{x_0 - x} 
    \quad \Rightarrow \quad 
    \underbrace{f(x)}_{?} = \underbrace{f(x_0)}_{\text{известно}} + \underbrace{f(x; x_0)}_{?} \underbrace{(x - x_0)}_{\text{известно}}. \tag{20}
\end{equation}

Нам нужно найти $f(x; x_0)$ справа — неизвестно. Это уравнение, причём неявное.

Привлечём другие РР:
\begin{equation}
    f(x; x_0; x_1) \overset{\text{по опр}}{=} \frac{f(x_0; x_1) - f(x; x_0)}{x_1 - x}
    \quad \Rightarrow \quad 
    f(x; x_0) = \underbrace{f(x_0; x_1)}_{\text{известно}} + \underbrace{f(x; x_0; x_1)}_{?} \underbrace{(x - x_1)}_{\text{известно}}. \tag{21}
\end{equation}

Снова получаем уравнение. Таким образом, подставляя (21) в (20):
\begin{equation}
    f(x) = f(x_0) + f(x_0; x_1)(x - x_0) + f(x; x_0; x_1)(x - x_0)(x - x_1). \tag{22}
\end{equation}

Соответственно, продолжая аналогичные действия, то есть вводя новый узел интерполяции и привлекая РР следующего порядка, за конечное число шагов, исчерпав все узлы интерполяции, мы придём к уравнению следующего вида:
\begin{equation}
    \begin{aligned}
    f(x) = & f(x_0) + f(x_0; x_1)(x - x_0) + f(x_0; x_1; x_2)(x - x_0)(x - x_1) + \dots \\
           & + f(x_0; x_1; \dots; x_n)(x - x_0)(x - x_1)\dots(x - x_{n-1}) \\
           & + \underbrace{f(x; x_0; x_1; \dots; x_n)}_{?}(x - x_0)(x - x_1)\dots(x - x_n). 
    \end{aligned}
\tag{23}
\end{equation}
кроме `?' все остальное известно.

\noindent\rule{\textwidth}{0.4pt}

Если у нас дано:
\[
P_n(x) = a_n x^n + \dots, \quad Q_m(x) = b_m x^m + \dots
\]
\[
P_n(x) \overset{?}{\equiv} Q_m(x) \iff 
\begin{cases}
    n = m, \\
    a_k = b_j, \quad \forall k = j.
\end{cases}
\tag{24}
\]

\noindent\rule{\textwidth}{0.4pt}

Обратим внимание, что в равенстве (23) в левой части стоит алгебраический многочлен степени $n$, а в правой части стоит многочлен.

Можем прийти к следующему выводу: для того чтобы равенство (23), как равенство двух алгебраических многочленов, выполнялось для всех значений аргумента $x$, необходимо, чтобы $f(x; x_0; x_1; \dots; x_n) \equiv 0$. В противном случае равенство (23) будет выполняться лишь в конечном числе точек.

В этой связи равенство (23) принимает следующий вид:
\begin{equation}
    \begin{aligned}
    f(x) = & f(x_0) + f(x_0; x_1)(x - x_0) + f(x_0; x_1; x_2)(x - x_0)(x - x_1) + \dots \\
           & + f(x_0; x_1; \dots; x_n)(x - x_0)(x - x_1)\dots(x - x_{n-1}).
    \end{aligned}
\tag{25}
\end{equation}

Получили аналитическую явную формулу.

Таким образом, в условиях сделанного предположения формула (25) позволила нам получить явное аналитическое выражение интерполируемой функции. 

Откажемся от сделанного предположения, т.е. будем считать, что $f(x)$ — произвольная интерполируемая функция. И наряду с такой функцией отдельно, то есть возьмём произвольную функцию $f(x)$ и многочлен $N_n(x)$:
\begin{equation}
    \begin{aligned}
    N_n(x) = & f(x_0) + f(x_0; x_1)(x - x_0) + f(x_0; x_1; x_2)(x - x_0)(x - x_1) + \dots \\
             & + f(x_0; x_1; \dots; x_n)(x - x_0)(x - x_1)\dots(x - x_{n-1}).
    \end{aligned}
\tag{26}
\end{equation}

Это --- интерполяционный многочлен в форме Ньютона.

Непосредственной подстановкой можно убедиться, что алгебраический многочлен (26) действительно удовлетворяет ГУИ:
\[
\begin{aligned}
    N_n(x_0) &\overset{(26)}{=} f(x_0) + f(x_0; x_1) \underbrace{(x - x_0)}_{=0} + 0 + \dots + 0 = f(x_0); \\
    N_n(x_1) &\overset{(26)}{=} f(x_0) + \frac{f(x_1) - f(x_0)}{x_1 - x_0} (x_1 - x_0) + 0 + \dots + 0 = f(x_1); \\
    N_n(x_2) &\overset{(26)}{=} \dots = f(x_2);
\end{aligned}
\tag{27}
\]
то есть $N_n(x)$ удовлетворяет ГУИ, а значит, является интерполяционным.


\textbf{23.09.25}

\section{Параграф 5 Интерполяция кубическими сплайнами}


\begin{figure} [H]
    \includegraphics[width=0.70\linewidth]{Без име2ни.png}
\end{figure}


$S_i (x)=a_i+b_i(x-x_{i-1})+c_i(x-x_{i-1})^2+d_i(x-x_{i-1})^3 $ (1)

$x \in (x_{i-1}, x_i)$

Сплайн — кусок, фрагмент чего-либо.

На каждом отрезке сформирован соседними узлами интерпоялции, определим
некоторой алгебраический многочлен третьей степени вида (1).

И поскольку каждый такой многочлен будем рассматривать исключительно на соответствущем
отрезке будем называть \textbf{кубическим сплаином} или алгебраическим многочленом третьей степени.

Сплайн - кусок, фрагмент чего либо.


\begin{figure} [H]
    \includegraphics[width=0.70\linewidth]{Без име24ни.png}
\end{figure}

\begin{figure} [H]
    \includegraphics[width=0.70\linewidth]{Без имени7.png}
\end{figure}


Потребуем что бы кусочная "склейка", указана кубических многочленов удовлетворила главному
условию интерполяции. А именно что бы каждый сплайн вида (1) удовлетворял следующем
равенствам.

Каждый левый сплайн должен пппринимать занчения левой точки(1)\dots

$$
\begin{cases}
    S_i (x_{i-1}) = f_{i-1}, & \quad i = \overline{1, n}  \\
    S_i (x_i) = f_i, & \quad i = \overline{1, n}
\end{cases}
\Leftrightarrow
\begin{cases}
    a_i = f_{i-1}, & \quad i = \overline{1, n}  \\
    a_i + b_i * h + c_i * h^2 + \alpha * h^3 = f_i, & \quad i = \overline{1, n}
\end{cases}
$$

CЛАУ относительно нев.выраж ${a_i,b_i,c_i,d_i}_{i= \overline{i,n}}$ (2) ур, отн 4n непр


Недостающие уравнения будем строить требуя не только не прирывной склейки самих  сплаинов, 
но и не прерывной склейки их производных в тех точках.

Для удобсвто дальнейшего использования заполним следующию таблицу
\begin{figure} [H]
    \includegraphics[width=0.70\linewidth]{photo_5375068150250467856_y.jpg}
\end{figure}

ля удобства дальнейшего использования заполним следующую таблицу:

\begin{center}
\renewcommand{\arraystretch}{1.5}
\small
\begin{tabular}{|c|c|}
\hline
$[x_{i-1}, x_i)$ & $[x_i, x_{i+1})$ \\
\hline
\parbox{0.45\textwidth}{\centering $S_i(x) = a_i + b_i(x - x_{i-1}) + c_i(x - x_{i-1})^2 + d_i(x - x_{i-1})^3$} & 
\parbox{0.45\textwidth}{\centering $S_{i+1}(x) = a_{i+1} + b_{i+1}(x - x_i) + c_{i+1}(x - x_i)^2 + d_{i+1}(x - x_i)^3$} \\
\hline
\parbox{0.45\textwidth}{\centering $S_i'(x) = b_i + 2c_i(x - x_{i-1}) + 3d_i(x - x_{i-1})^2$} & 
\parbox{0.45\textwidth}{\centering $S_{i+1}'(x) = b_{i+1} + 2c_{i+1}(x - x_i) + 3d_{i+1}(x - x_i)^2$} \\
\hline
\parbox{0.45\textwidth}{\centering $S_i''(x) = 2c_i + 6d_i(x - x_{i-1})$} & 
\parbox{0.45\textwidth}{\centering $S_{i+1}''(x) = 2c_{i+1} + 6d_{i+1}(x - x_i)$} \\
\hline
\end{tabular}
\end{center}

Обозначим $h = x_i - x_{i-1}$ (предполагаем равномерную сетку).

Теперь потребуем непрерывность склейки первых производных в точках склейки:
\begin{equation}
    S_i'(x_i) = S_{i+1}'(x_i), \quad i = 1, \dots, n-1. \tag{32}
\end{equation}

Также потребуем непрерывность склейки вторых производных в точках склейки:
\begin{equation}
    S_i''(x_i) = S_{i+1}''(x_i), \quad i = 1, \dots, n-1. \tag{33}
\end{equation}

Условия (32) и (33) дают систему:
\[
\begin{cases}
    S_i'(x_i) = S_{i+1}'(x_i), & i = 1, \dots, n-1, \\
    S_i''(x_i) = S_{i+1}''(x_i), & i = 1, \dots, n-1,
\end{cases}
\]
что эквивалентно:
\[
\begin{cases}
    b_i + 2c_i h + 3d_i h^2 = b_{i+1}, & i = 1, \dots, n-1, \\
    2c_i + 6d_i h = 2c_{i+1}, & i = 1, \dots, n-1.
\end{cases} \tag{34}
\]

Таким образом получаем два набора уравнений:
\begin{equation}
    b_i + 2c_i h + 3d_i h^2 = b_{i+1}, \quad i = 1, \dots, n-1, \tag{35}
\end{equation}
\begin{equation}
    2c_i + 6d_i h = 2c_{i+1}, \quad i = 1, \dots, n-1. \tag{36}
\end{equation}

По своей алгебраической природе равенства (35) и (36) объединяют коэффициенты соседних сплайнов, давая $(n-1) + (n-1) = 2n - 2$ уравнений. 

Ранее из условий интерполяции мы имели $2n$ уравнений:
\[
\begin{cases}
    S_i(x_{i-1}) = y_{i-1}, & i = 1, \dots, n, \quad \text{(30)} \\
    S_i(x_i) = y_i, & i = 1, \dots, n, \quad \text{(31)}
\end{cases}
\]
Всего имеем: $2n + (2n - 2) = 4n - 2$ уравнений относительно $4n$ неизвестных $\{a_i, b_i, c_i, d_i\}_{i=1}^n$.

Недостающие 2 уравнения получим из так называемого условия нулевой кривизны (УНК) для $S_1(x)$ в точке $x_0$ и $S_n(x)$ в точке $x_n$, что может быть записано как:
\[
\begin{cases}
    S_1''(x_0) = 0, \\
    S_n''(x_n) = 0,
\end{cases}
\quad \Leftrightarrow \quad
\begin{cases}
    2c_1 = 0, \\
    2c_n + 6d_n \cdot h = 0.
\end{cases} \tag{37}
\]

То есть:
\begin{align}
    & S_1''(x_0) = 0, \tag{38} \\
    & S_n''(x_n) = 0, \tag{39} \\
    & 2c_1 = 0, \tag{40} \\
    & 2c_n + 6d_n \cdot h = 0. \tag{41}
\end{align}

Таким образом, мы получили СЛАУ размерности $4n \times 4n$, состоящую из уравнений (30), (31), (35), (36), (40), (41). Можно убедиться, что главный определитель будет отличен от нуля, а следовательно, система будет иметь единственное решение.

Соответственно, решив данную СЛАУ любым подходящим численным методом, мы сможем найти искомые коэффициенты $\{a_i, b_i, c_i, d_i\}_{i=1}^n$ для сплайнов, определяемых по формуле:
\[
S_i(x) = a_i + b_i(x - x_{i-1}) + c_i(x - x_{i-1})^2 + d_i(x - x_{i-1})^3, \quad x \in [x_{i-1}, x_i]. \tag{28}
\]


\begin{figure} [H]
    \includegraphics[width=0.70\linewidth]{photo_5375068150250467857_y.jpg}
\end{figure}

\vspace{20mm}

\textbf{07.10.25}

\section{Раздел 2}
\section{Решение СЛАУ Метод Гаусса}

$a_{11} \neq 0, a_{22}^{(1)} \neq 0, a_{33}^{(2)} \neq 0,... a_{nn}^{(n-1)} \neq 0$

Соответсвенно если на каждом прямого хода мы встретим элемент $a_{kk_1}^{(k-1)} \equiv 0$ 
$(a_{kk_1}^{(k-1)} \in 0_\delta = (-\delta; \delta))$

Любое число из этого интеравала будет 0

\begin{figure} [H]
    \includegraphics[width=0.70\linewidth]{Без имени8.png}
\end{figure}


Рассмотрим СЛАУ следующего вида:

\begin{equation}
\left\{
\begin{aligned}
    a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n &= b_1 \\
    a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n &= b_2 \\
    &\ \vdots \\
    a_{n1}x_1 + a_{n2}x_2 + \dots + a_{nn}x_n &= b_n
\end{aligned}
\right.
\tag{42}
\end{equation}

Систему (42) можно записать в матричном виде:
\begin{equation}
A\mathbf{x} = \mathbf{b},
\tag{43}
\end{equation}
где 
\begin{equation*}
A = 
\begin{pmatrix}
a_{11} & a_{12} & \dots & a_{1n} \\
a_{21} & a_{22} & \dots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \dots & a_{nn}
\end{pmatrix}, \quad
\mathbf{b} = 
\begin{pmatrix}
b_1 \\
b_2 \\
\vdots \\
b_n
\end{pmatrix}, \quad
\mathbf{x} = 
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix}.
\end{equation*}

Вектор $\mathbf{x}$ является решением системы (неизвестным):
\begin{equation}
\mathbf{x} = \ ? \tag{44}
\end{equation}

Расширенная матрица коэффициентов СЛАУ (42) имеет вид:
\begin{equation}
(A|\mathbf{b}) = 
\left(
\begin{array}{cccc|c}
a_{11} & a_{12} & \dots & a_{1n} & b_1 \\
a_{21} & a_{22} & \dots & a_{2n} & b_2 \\
\vdots & \vdots & \ddots & \vdots & \vdots \\
a_{n1} & a_{n2} & \dots & a_{nn} & b_n
\end{array}
\right).
\tag{45}
\end{equation}

Далее будем предполагать, что СЛАУ (42) имеет единственное решение.

Метод Гаусса условно подразделяют на 2 последовательных этапа:
\begin{enumerate}
    \item Прямой ход
    \item Обратный ход
\end{enumerate}
Рассмотрим их подробнее.

\subsection{Прямой ход Методом Гаусса}

Сутью прямого хода является преобразование расширенной матрицы коэффициентов (PMK) системы (42) к так называемому верхнему треугольному виду:

\begin{equation}
\left(
\begin{array}{cccc|c}
1 & * & * & * & * \\
0 & 1 & a_{ij} & * & * \\
0 & 0 & 1 & * & b_i \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1 \\
\end{array}
\right)
\tag{46}
\end{equation}

где $*$ обозначает возможные ненулевые элементы (кроме единиц на главной диагонали), $a_{ij}$ и $b_i$ --- некоторые преобразованные коэффициенты.

В полученной системе:
\[
(x_1, x_2, \dots, x_n) \quad \text{--- уравнения с одним неизвестным } x_n \text{ в последней строке}.
\]


\textbf{21.10.25}

В предыдущем параграфе мы рассмотрели базовую конструкцию метода Гаусса, в рамках которой на прямом ходе мы попутно делали предположения, что $a_{11} \neq 0$, и в результате мы могли делить строку на $a_{11}$, и что $a^{(1)}_{22} \neq 0$; с такой же целью и $a^{(2)}_{33} \neq 0$; $\dots$ $a^{(n-1)}_{nn} \neq 0$.

Соответственно, если на $k$-ом шаге прямого хода мы встретим $a^{(k-1)}_{kk} \equiv 0$ ($a^{(k-1)}_{kk} \in O_\delta = (-\delta, \delta)$),
\[
\left(
\begin{array}{ccccccc}
1 & * & * & \cdots & * & * & * \\
0 & 1 & * & \cdots & * & * & * \\
0 & 0 & 1 & \cdots & * & * & * \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & a^{(k-1)}_{kk} & * & * \\
0 & 0 & 0 & \cdots & a^{(k-1)}_{(k+1)k} & * & * \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & \cdots & a^{(k-1)}_{nk} & * & * \\
\end{array}
\right)
\]
В этом случае в строках с $k+1, \dots, n$ ищут элемент
\begin{equation}
a^{(k-1)}_{mk} = \max_{k+1 \leq j \leq n} |a_{jk}|. \tag{47}
\end{equation}

\begin{enumerate}
    \item Если $a^{(k-1)}_{mk} \neq 0$ ($\notin (-\delta, \delta)$), то меняют местами $k$-ую и $m$-ую строки РМК. В этом случае в позиции $(k, k)$ $a^{(k-1)}_{mk} \neq 0$ ($\notin (-\delta, \delta)$), и прямой ход метода Гаусса может быть продолжен. Т.е. нормировка строки будет возможна.
    
    \item Если $a^{(k-1)}_{mk} = 0$ ($\in (-\delta, \delta)$), тогда перестановка строк не решает проблему. И в этом случае ищут элемент
    \begin{equation}
    a^{(k-1)}_{km} = \max_{k+1 \leq j \leq n} |a_{kj}|. \tag{48}
    \end{equation}
    и в этом случае, если $a^{(k-1)}_{km} \neq 0$ ($\notin (-\delta, \delta)$), то меняют $k$-й и $m$-й столбцы.
\end{enumerate}

Таким образом, если элементы, определённые по формулам (47) и (48), будут равны 0, то прямой ход метода Гаусса будет вынужденно приостановлен ввиду невозможности произвести нормировку соответствующего диагонального элемента.

В случае перестановки столбцов в РМК параллельно необходимо запоминать соответствующую перестановку в векторе $\mathbf{x}$, с тем чтобы после завершения уже после обратного хода выполнить обратную перестановку неизвестных, вернув им натуральный порядок нумерации.

\textbf{6.1.2 Нахождение определителя квадратной матрицы $A_{n \times n}$}

\[
A = \begin{pmatrix}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{pmatrix}_{2\times 2} \quad \rightarrow \quad \Delta = a_{11}a_{22} - a_{12}a_{21}. \tag{49}
\]

\[
A = \begin{pmatrix}
a_{11} & a_{12} & a_{13} \\
a_{21} & a_{22} & a_{23} \\
a_{31} & a_{32} & a_{33}
\end{pmatrix}_{3\times 3} \quad \rightarrow \quad 
\begin{aligned}
\Delta &= a_{11}a_{22}a_{33} + a_{21}a_{32}a_{13} + a_{12}a_{23}a_{31} \\
       &\quad - a_{13}a_{22}a_{31} - a_{21}a_{12}a_{33} - a_{32}a_{23}a_{11}.
\end{aligned} \tag{50}
\]

\[
A_{n\times n} \quad \rightarrow \quad \Delta \sim n! \tag{51}
\]

Таким образом, с ростом размерности матрицы $n$ число операций, необходимое для нахождения определителя этой матрицы по классической формуле, растёт довольно заметно.

Применим к матрице $A_{n\times n}$ процедуру диагонализации, позаимствованную из метода Гаусса:
\[
A_{n\times n} = 
\begin{pmatrix}
a_{11} & \dots & a_{1n} \\
\vdots & \ddots & \vdots \\
a_{n1} & \dots & a_{nn}
\end{pmatrix}
\sim \xrightarrow[\text{эквив. преобр.}]{\text{над матриц.}} \dots \sim
\begin{pmatrix}
1 & * & \dots & * \\
0 & 1 & \dots & * \\
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \dots & 1
\end{pmatrix}. \tag{52}
\]

При этом вспомним, что в процедуре диагонализации матрицы применяются следующие эквивалентные преобразования:
\begin{enumerate}
    \item Умножение строки на $\frac{1}{a^{(k-1)}_{kk}}$
    \item Прибавление к строке другой строки, умноженной на $\lambda \neq 0$
    \item Перестановка строк или столбцов (в процедуре выбора главного элемента)
\end{enumerate}

Таким образом, после завершения процедуры диагонализации исходной матрицы $A$ её исходный определитель будет подвергнут следующим преобразованиям:
\[
\frac{\Delta}{a_{11} \cdot a^{(1)}_{22} \cdot a^{(2)}_{33} \cdot \ldots \cdot a^{(n-1)}_{nn}} = (-1)^\nu \cdot \underbrace{\Delta_\sim}_{=1}, \tag{53}
\]
\begin{equation}
\Delta = (-1)^\nu \cdot a_{11} \cdot a^{(1)}_{22} \cdot a^{(2)}_{33} \cdot \ldots \cdot a^{(n-1)}_{nn}, \tag{54}
\end{equation}
где $\nu$ — количество реализованных перестановок при выборе главного элемента (ПВГЭ).

\paragraph*{Замечание.} Отметим, что для того чтобы воспользоваться формулой (54), необходимо узнать нормирующие коэффициенты $a^{(1)}_{22}, a^{(2)}_{33}, \dots, a^{(n-1)}_{nn}$, для чего необходимо $\dots$


\section{Метод прогонки. Решение трехдиагональных СЛАУ}

Рассмотрим СЛАУ следующего вида:
\begin{equation}
\begin{cases}
    a_i \cdot x_{i-1} - b_i x_i + c_i x_{i+1} = d_i, \quad i = 1, \dots, n, \\
    a_1 = c_n = 0.
\end{cases}
\tag{55}
\end{equation}

Или подробнее:
\begin{align}
    a_i \cdot x_{i-1} - b_i x_i + c_i x_{i+1} &= d_i, \quad i = 1, \dots, n, \tag{56} \\
    a_1 = c_n &= 0. \tag{57}
\end{align}

Запишем СЛАУ (56)–(57) в матричной форме:
\begin{equation}
\begin{pmatrix}
-b_1 & c_1 & 0 & \dots & 0 \\
a_2 & -b_2 & c_2 & \dots & 0 \\
0 & a_3 & -b_3 & \dots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \dots & -b_n
\end{pmatrix}_{n\times n}
\cdot
\begin{pmatrix}
x_1 \\ x_2 \\ \vdots \\ x_n
\end{pmatrix}_{n\times 1}
=
\begin{pmatrix}
d_1 \\ d_2 \\ \vdots \\ d_n
\end{pmatrix}_{n\times 1}.
\tag{58}
\end{equation}

Запишем расширенную матрицу коэффициентов (РМК) СЛАУ (58):
\begin{equation}
\left(
\begin{array}{cccccc|c}
-b_1 & c_1 & 0 & \dots & 0 & 0 & d_1 \\
a_2 & -b_2 & c_2 & \dots & 0 & 0 & d_2 \\
0 & a_3 & -b_3 & \dots & 0 & 0 & d_3 \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & \dots & a_n & -b_n & d_n
\end{array}
\right)
\sim \dots \sim
\left(
\begin{array}{cccccc|c}
* & * & 0 & \dots & 0 & 0 & * \\
0 & * & * & \dots & 0 & 0 & * \\
0 & 0 & * & \dots & 0 & 0 & * \\
\vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
0 & 0 & 0 & \dots & 0 & * & *
\end{array}
\right).
\tag{59}
\end{equation}

\textbf{Результирующая РМК после прямого метода Гаусса.}

Если к СЛАУ вида (58) применить в лоб прямой ход метода Гаусса, то в результате него трехдиагональная РМК СЛАУ (58) будет преобразована к двухдиагональной итоговой РМК. При этом нулевые элементы, стоящие вне исходных ненулевых диагоналей, будут преобразованы снова в нулевые элементы (при этом нижняя из 3 диагоналей будет обнулена; а две оставшиеся изменят свои значения). Также нулевые элементы, расположенные выше двух полученных диагоналей в результате прямого хода метода Гаусса, не смогут оказать влияния на итоговый результат (т.к. линейная комбинация нулей есть ноль).

В связи с чем поставим перед собой цель оптимизировать метод Гаусса применительно к случаю систем вида (58). А именно, попытаемся его усовершенствовать, устранив лишние «операции» по преобразованию нулевых элементов в себя. При этом мы откажемся от лобового применения метода Гаусса, используя при этом его конечный результат: а именно то, что после прямого хода уравнения примут двухкомпонентный вид
\begin{equation}
    x_i = \underbrace{P_{i+1}}_{?} x_{i+1} + \underbrace{Q_{i+1}}_{?}, \quad i = 1, \dots, n \quad \text{--- ($i$-е уравнение)}.
\tag{60}
\end{equation}

Обратив внимание, что в $i$-ом уравнении вида (56) в результате его преобразования к виду (60) исчезает компонента $x_{i-1}$, однако эта неизвестная присутствует в $(i-1)$-ом уравнении вида (60), которое имеет вид:
\begin{equation}
    x_{i-1} = P_i x_i + Q_i \quad \text{--- ($i-1$)-е уравнение}.
\tag{61}
\end{equation}

Соответственно, подставив выражение (61) для $(i-1)$-го уравнения в уравнение (56), получим еще один (уже третий) способ записи $i$-го уравнения:
\begin{equation}
    a_i (P_i x_i + Q_i) - b_i x_i + c_i x_{i+1} = d_i \quad \text{--- $i$-е уравнение в третьей форме записи}.
\tag{62}
\end{equation}
\begin{equation}
    a_i P_i x_i + a_i Q_i - b_i x_i + c_i x_{i+1} = d_i,
    \qquad (a_i P_i - b_i) x_i = -c_i x_{i+1} + (d_i - a_i Q_i).
\tag{63}
\end{equation}
\begin{equation}
    x_i = \frac{c_i}{b_i - a_i P_i} \cdot x_{i+1} + \frac{a_i Q_i - d_i}{b_i - a_i P_i} \quad \text{--- $i$-е уравнение в 4-й форме записи}.
\tag{64}
\end{equation}

Сравнивая две различные формы записи одного и того же $i$-го уравнения, а именно (60) и (64), мы можем прийти к следующим равенствам соответствующих коэффициентов:
\begin{equation}
    P_{i+1} = \frac{c_i}{b_i - a_i P_i}, \qquad
    Q_{i+1} = \frac{a_i Q_i - d_i}{b_i - a_i P_i}.
\tag{65}
\end{equation}

Рассмотрим формулы (65) применительно к первому уравнению ($i=1$):
\begin{align}
    P_2 &= \frac{c_1}{b_1 - a_1 P_1}, \tag{66} \\
    Q_2 &= \frac{a_1 Q_1 - d_1}{b_1 - a_1 P_1}. \tag{67}
\end{align}
Учитывая, что $a_1 = 0$, получаем:
\begin{equation}
    P_2 = \frac{c_1}{b_1}, \qquad
    Q_2 = -\frac{d_1}{b_1}.
\tag{68}
\end{equation}

Таким образом, используя формулы (65) и (68), мы можем однозначным образом задать искомые значения коэффициентов двухкомпонентных уравнений вида (60) в следующей последовательности:
\begin{equation}
    \underbrace{(P_2, Q_2)}_{\text{из (68)}} 
    \xrightarrow{\text{по (65)}} 
    (P_3, Q_3) 
    \xrightarrow{\text{по (65)}} 
    \dots 
    \xrightarrow{\text{по (65)}} 
    (P_n, Q_n) 
    \xrightarrow{\text{по (65)}} 
    Q_{n+1}.
\tag{69}
\end{equation}

Таким образом, узнав коэффициенты двухкомпонентных уравнений вида (60), мы сможем реализовать обратный ход (но не построчный) по следующим формулам:
\begin{align}
    x_n &= Q_{n+1}, \tag{70} \\
    &\begin{cases}
        x_{n-1} = P_n x_n + Q_n, \\
        x_{n-2} = P_{n-1} x_{n-1} + Q_{n-1}, \\
        \dots \\
        x_1 = P_2 x_2 + Q_2.
    \end{cases}
\tag{71}
\end{align}

Из вышеизложенного можем выделить следующий алгоритм метода прогонки:

\textbf{7.1.1. Этап 1 (прямая прогонка)}
Он состоит в нахождении прогоночных коэффициентов:
\begin{equation}
    (P_2, Q_2),\, (P_3, Q_3),\, \dots,\, (P_n, Q_n),\, Q_{n+1}.
\tag{72}
\end{equation}

\textbf{7.1.2. Этап 2 (обратная прогонка)}
Нахождение $x_i$ по формулам (70) и (71).

Структурно формулы (68), (65), а также (70) и (71) являются рекуррентными соотношениями.

Метод прогонки — это оптимизированный метод Гаусса для систем специального трехдиагонального вида.

\section{Метод простой интерации. Решения СЛАУ}

Ax=b (1)

Покажем что СЛАУ(1) к слеудющему эквиваленному виду $x =\alpha * \chi + \beta(2)$

Одним из спосбов преобразлвания СЛАУ из (1) к (2) может быть следующие:

В каждом уравнении системы (1) в левой части равенста, остовляют ту компоненту искомоого вектора x, 
что имеет номер текущего уравнения, а именно каждое уравнение записываем в виде

$\chi_i=\frac{1}{a_{ii}}(b_i - \sum_{i=1}^{i-1}a_{ij}\chi_j - \sum_{j-i+1}^{n} a_{ij}\chi_j), i=\overline{1,n} (1')$

Перепеишем систему (1')в матричном ввиде
тут матрица втсавить 

Таким образом развернутая система в виде(2') показыват что СЛАУ (1) может быть преобразована 
кэквивалетному ввиду (2), другими словами решить СЛАУ(1), что и решить СЛАУ (2).

Метод простой итерцаии (МПИ) решеени (2) основан на итерационном (рекурсинвом повторяющимя), 
построении последовательности векторов. 


Тут кое-что переработанное, может содержать дубликаты
\begin{equation}
    A\mathbf{x} = \mathbf{b}. \tag{73}
\end{equation}
Предполагая, что у данной системы существует единственное решение.

Покажем, что СЛАУ вида (73) может быть преобразована к следующему эквивалентному виду
\begin{equation}
    \mathbf{x} = \alpha \cdot \mathbf{x} + \beta. \tag{74}
\end{equation}

Одним из способов преобразования СЛАУ вида (73) к (74) может быть следующий:
В каждом уравнении системы (73) в левой части равенства оставляем ту компоненту вектора $\mathbf{x}$, что имеет номер текущего уравнения. А именно, каждое уравнение записываем в виде:
\begin{equation}
    x_i = \frac{1}{a_{ii}} \Bigl( b_i - \sum_{j=1}^{i-1} a_{ij}x_j - \sum_{j=i+1}^{n} a_{ij}x_j \Bigr), \quad i = 1, \dots, n. \tag{75}
\end{equation}

Перепишем систему (75) в матричном виде:
\begin{equation}
    \underbrace{
    \begin{pmatrix}
        x_1 \\
        x_2 \\
        \vdots \\
        x_n
    \end{pmatrix}
    }_{\mathbf{x}}
    =
    \underbrace{
    \begin{pmatrix}
        0 & -\frac{a_{12}}{a_{11}} & -\frac{a_{13}}{a_{11}} & \dots & -\frac{a_{1n}}{a_{11}} \\[3pt]
        -\frac{a_{21}}{a_{22}} & 0 & -\frac{a_{23}}{a_{22}} & \dots & -\frac{a_{2n}}{a_{22}} \\[3pt]
        \vdots & \vdots & \vdots & \ddots & \vdots \\[3pt]
        -\frac{a_{n1}}{a_{nn}} & -\frac{a_{n2}}{a_{nn}} & -\frac{a_{n3}}{a_{nn}} & \dots & 0
    \end{pmatrix}
    }_{\alpha}
    \cdot
    \underbrace{
    \begin{pmatrix}
        x_1 \\
        x_2 \\
        \vdots \\
        x_n
    \end{pmatrix}
    }_{\mathbf{x}}
    +
    \underbrace{
    \begin{pmatrix}
        \frac{b_1}{a_{11}} \\[3pt]
        \frac{b_2}{a_{22}} \\[3pt]
        \vdots \\[3pt]
        \frac{b_n}{a_{nn}}
    \end{pmatrix}
    }_{\beta}. \tag{76}
\end{equation}

Таким образом, развёрнутая система в виде (76) показывает, что СЛАУ (73) может быть преобразована к эквивалентному виду (74). Другими словами, решить (73) — это то же самое, что решить СЛАУ (75).

Метод простой итерации (МПИ) решения СЛАУ (74) основан на итерационном (рекурсивном, повторяющемся) построении последовательности векторов
\begin{equation}
    \{\mathbf{x}^{(k)}\}_{k=0}^\infty. \tag{77}
\end{equation}
по следующей формуле (формула МПИ):
\begin{equation}
    \{\mathbf{x}^{(k)}\}_{k=0}^\infty : \quad \mathbf{x}^{(k+1)} = \alpha \cdot \mathbf{x}^{(k)} + \beta, \quad \text{где } \mathbf{x}^{(0)} \text{ — задан некоторым образом}. \tag{78}
\end{equation}

Предположим, что есть вектор $\mathbf{x}^{(0)}$, и вектор $\mathbf{x}^{(*)}$ — точное решение. \\
Строим вектора $\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \dots, \mathbf{x}^{(k)}, \mathbf{x}^{(k+1)}$, и они сгущаются около вектора $\mathbf{x}^{(*)}$. \\
Разница $\mathbf{x}^{(*)}$ и $\mathbf{x}^{(0)}$ равна $\boldsymbol{\varepsilon}^{(0)}$, \\
Разница $\mathbf{x}^{(*)}$ и $\mathbf{x}^{(1)}$ равна $\boldsymbol{\varepsilon}^{(1)}$, и т.д. по индукции.

Выясним, при каких условиях последовательность векторов $\{\mathbf{x}^{(k)}\}_{k=0}^\infty$ будет сходиться к точному решению $\mathbf{x}^{(*)}$ системы (74). При этом значение начального вектора $\mathbf{x}^{(0)}$ будем считать заданным, но пока неизвестным для себя образом.

Так как $\mathbf{x}^{(*)}$ есть точное решение СЛАУ (74), то имеет место следующее тождество:
\begin{equation}
    \mathbf{x}^{(*)} = \alpha \cdot \mathbf{x}^{(*)} + \beta. \tag{79}
\end{equation}

Составим разность равенств (79) и (78) при некотором фиксированном $k$:
\begin{equation}
    \underbrace{\mathbf{x}^{(*)} - \mathbf{x}^{(k+1)}}_{\boldsymbol{\varepsilon}^{(k+1)}} 
    = \alpha \cdot \underbrace{(\mathbf{x}^{(*)} - \mathbf{x}^{(k)})}_{\boldsymbol{\varepsilon}^{(k)}} 
    \quad \Leftrightarrow \quad 
    \boldsymbol{\varepsilon}^{(k+1)} = \alpha \cdot \boldsymbol{\varepsilon}^{(k)}, \quad \forall k = 0, 1, 2, \dots \tag{80}
\end{equation}

Используя представление (80), получим:
\begin{equation}
    \begin{cases}
        \boldsymbol{\varepsilon}^{(1)} = \alpha \cdot \boldsymbol{\varepsilon}^{(0)}, \\
        \boldsymbol{\varepsilon}^{(2)} = \alpha \cdot \boldsymbol{\varepsilon}^{(1)} = \alpha \cdot \alpha \cdot \boldsymbol{\varepsilon}^{(0)} = \alpha^2 \cdot \boldsymbol{\varepsilon}^{(0)}, \\
        \boldsymbol{\varepsilon}^{(3)} = \alpha \cdot \boldsymbol{\varepsilon}^{(2)} = \alpha \cdot \alpha^2 \cdot \boldsymbol{\varepsilon}^{(0)} = \alpha^3 \cdot \boldsymbol{\varepsilon}^{(0)}, \\
        \dots \\
        \boldsymbol{\varepsilon}^{(k+1)} = \alpha \cdot \boldsymbol{\varepsilon}^{(k)} = \alpha \cdot \alpha^k \cdot \boldsymbol{\varepsilon}^{(0)} = \alpha^{k+1} \cdot \boldsymbol{\varepsilon}^{(0)}, \quad \forall k = 0, 1, 2, \dots
    \end{cases} \tag{81}
\end{equation}

Таким образом, мы имеем последовательность векторов-погрешностей $\{\boldsymbol{\varepsilon}^{(k)}\}_{k=0}^\infty$, определяемую по формуле (81) или (80).

Пусть $\rho(\mathbf{x}, \mathbf{y}) = \|\mathbf{y} - \mathbf{x}\|$ — норма.
\begin{equation}
    \tag{82}
\end{equation}

Согласно «известному факту», для того чтобы последовательность векторов сходилась к предельному вектору, необходимо чтобы последовательность норм этих векторов сходилась к соответствующей норме предельного вектора. В этой связи в векторном равенстве (81) перейдем к соответствующему равенству норм:
\begin{equation}
    \|\boldsymbol{\varepsilon}^{(k+1)}\| = \| \underbrace{\alpha^{k+1}}_{\in \mathbb{R}^{n\times n}} \cdot \boldsymbol{\varepsilon}^{(0)} \|. \tag{83}
\end{equation}

\begin{equation}
\begin{aligned}
\|\boldsymbol{\varepsilon}^{(k+1)}\|
&= \| \underbrace{\alpha^{k+1}}_{\in \mathbb{R}^{n\times n}} \cdot \underbrace{\boldsymbol{\varepsilon}^{(0)}}_{\in \mathbb{R}^{n}} \| \\
&\leqslant \|\alpha^{k+1}\|_{\mathbb{R}^{n\times n}} \cdot \|\boldsymbol{\varepsilon}^{(0)}\|_{\mathbb{R}^{n}} \quad \text{— условие согласованности норм}.
\end{aligned}
\tag{84}
\end{equation}

Из последней цепочки равенств/неравенств получаем:
\begin{equation}
    \|\boldsymbol{\varepsilon}^{(k+1)}\| \leqslant \|\alpha\|^{k+1} \cdot \|\boldsymbol{\varepsilon}^{(0)}\|, \quad \forall k = 0, 1, 2, \dots \tag{85}
\end{equation}
(выполняется при условии согласованности норм).

Следовательно, последовательность векторов $\{\boldsymbol{\varepsilon}^{(k+1)}\}_{k=0}^\infty$ будет стремиться к $\mathbf{0}_{\mathbb{R}^n}$. Другими словами, последовательность векторов $\{\mathbf{x}^{(*)} - \mathbf{x}^{(k+1)}\}_{k=0}^\infty \to \mathbf{0}_{\mathbb{R}^n} \;\Leftrightarrow\; \{\mathbf{x}^{(k+1)}\} \to \mathbf{x}^{(*)}$.

Таким образом, из вышеизложенного получаем:

Чтобы последовательность векторов $\{\mathbf{x}^{(k)}\}_{k=0}^\infty$, вычисляемых по итерационной формуле (78), сходилась к точному решению СЛАУ (74) — $\mathbf{x}^{(*)}$, необходимо
\begin{enumerate}
    \item наличие условия на норму матрицы $\alpha$: $\|\alpha\| < 1$;
        \begin{equation} \tag{86} \end{equation}
    \item согласованность используемых норм в $\mathbb{R}^n$ и $\mathbb{R}^{n\times n}$.
\end{enumerate}


\textbf{11.11.25}

I

%$\left\{y'(x)= f(x,y(x)) (1)$ - ОРУ 1 параграф отн $y=y(x)-? y(x_0) = y_0 (2)$ - нач цел.$\right\} тут должна быть система, но я не понмю как это оформляется 


$y_1'(x) = f_1(x,y_1(x),y_2(x))$

$y_2'(x) = f_2(x,y_1(x),y_2(x))$

$y_1(x_0) = y_1^0$

$y_2(x_0) = y_2^0$

тут тоже систмеа

Согласно известной теормее о сущетсвовании и еиднственности о существование и единственности решенения 
задачи Коши. Задача 1.2 при некоторых условиях на функции f(.,.) некоторой окрестности $O_{x_0}^{f} y(x)$, такое что
y(x)- диф. + y(x) уд ОДУ (1) + y(x) уд НУ (2)

В этой связи что мы рассматриваем задачу 1.2 в указанной окрестности, где азадачи Коши имеет  
единвтсенное решение. 

Каши звали Гюст, лол это пороль на экзамен. ПАРОЛЬ пряник предположим аахах


\begin{figure} [H]
    \includegraphics[width=0.70\linewidth]{Без именци.png}
\end{figure}

Покажем что задача Коши 1.2 может быть преобразловна к некоторыму итнтегральному уравнению. С этой целью проинтерегриуем 
ОДУ (1) по отрезку $[x_0,x]\in O_{x_0}^f$ 
В результате получаем, 
$\int_{x_0}^{x}y(\xi)d\xi= \int_{x_0}^{x} f(\xi,y(\xi))d\xi$

Ф.Н.-Л.

$\int_{a}^{}b f(x)dx=F(b)-F(u) $

$F'(x)=f(x)$

$f(x\leftrightarrows F(x))$

$y(x)=y(x_0)+ \int_{x_0}^{x} f(\xi,y(\xi))d\xi$ (3)

Таким образом y(x) - решешние задачи Коши (1)(2), то решение И.У (3)

y(x) - решение б.р З.К (1)(2)
имеено в этом смлысле мы будем понимать эквивалеьность ИУ ...


II Усоврешествнанный метод Эйлера



\section{Параграф 3}

\subsection{Метод не определенных коэфецентов решеений краевой задачи}


\section{Раздел 4}

\subsection{Численные методы решений интегральных уравнений}

\subsubsection{Параграф . Решение интегральных уравнений Фредогольма в случае выражденого ядра}










\end{document}